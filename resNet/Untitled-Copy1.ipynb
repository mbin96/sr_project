{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "16 32 2\n",
      "32 64 2\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.autograd import Variable\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomCrop(32),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     normalize])\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=768,\n",
    "                                          shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=512,\n",
    "                                         shuffle=False, num_workers=2,pin_memory=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='B'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            print(in_planes, self.expansion * planes, stride)\n",
    "            self.shortcut = nn.Sequential(\n",
    "                 nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                 nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        out = self.bn1(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "# class resNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(resNet, self).__init__()\n",
    "#         self.conv0 = nn.Conv2d(3, 16, 3, padding = 1, bias=False)\n",
    "#         self.bn0   = nn.BatchNorm2d(16)\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(16, 16, 3, padding = 1, bias=False)\n",
    "#         self.bn1   = nn.BatchNorm2d(16)\n",
    "        \n",
    "#         self.reDem12 = nn.Conv2d(16, 32, 1, stride = 2, bias=False)\n",
    "#         self.conv2_t = nn.Conv2d(16, 32, 3, stride = 2, padding = 1, bias=False)\n",
    "#         self.conv2_m = nn.Conv2d(32, 32, 3, padding = 1, bias=False)\n",
    "#         self.bn2     = nn.BatchNorm2d(32)\n",
    "        \n",
    "#         self.reDem23 = nn.Conv2d(32, 64, 1, stride = 2, bias=False)\n",
    "#         self.conv3_t = nn.Conv2d(32, 64, 3, stride = 2, padding = 1, bias=False)\n",
    "#         self.conv3_m = nn.Conv2d(64, 64, 3, padding = 1, bias=False)\n",
    "#         self.bn3     = nn.BatchNorm2d(64)\n",
    "        \n",
    "#         #self.maxPool  = nn.MaxPool2d(3, stride = 2, padding = 1)\n",
    "#         self.avg_pool = nn.AvgPool2d(8, stride = 1)\n",
    "#         self.linear = nn.Linear(64, 10)\n",
    "#         self.fc = nn.Linear(8*8, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         #conv0 224 -> 56\n",
    "#         x = F.relu(self.bn0(self.conv0(x)))\n",
    "\n",
    "#         #conv1 \n",
    "#         for i in range(9):\n",
    "#             out = self.bn1(self.conv1(F.relu(self.bn1(self.conv1(x)))))\n",
    "#             # residual addiction\n",
    "#             x = x + out\n",
    "#             # relu result\n",
    "#             x = F.relu(x)\n",
    "\n",
    "#         #conv2\n",
    "#         out = self.bn2(self.conv2_m(F.relu(self.bn2(self.conv2_t(x)))))\n",
    "#         # residual addiction\n",
    "#         x = out + self.bn2(self.reDem12(x))\n",
    "#         # relu result\n",
    "#         x = F.relu(x)\n",
    "#         for i in range(8):\n",
    "#             out = self.bn2(self.conv2_m(F.relu(self.bn2(self.conv2_m(x)))))\n",
    "#             # residual addiction\n",
    "#             x = x + out\n",
    "#             # relu result\n",
    "#             x = F.relu(x)\n",
    "\n",
    "#         #conv3\n",
    "        \n",
    "#         out = self.bn3(self.conv3_m(F.relu(self.bn3(self.conv3_t(x)))))\n",
    "#         # residual addiction\n",
    "#         x = out + self.bn3(self.reDem23(x))\n",
    "#         # relu result\n",
    "#         x = F.relu(x)\n",
    "#         for i in range(8):\n",
    "#             out = self.bn3(self.conv3_m(F.relu(self.bn3(self.conv3_m(x)))))\n",
    "#             # residual addiction\n",
    "#             x = x + out\n",
    "#             # relu result\n",
    "#             x = F.relu(x)\n",
    "\n",
    "#         #fully connected\n",
    "# #         x = self.avg_pool(x)\n",
    "# #         x = torch.flatten(x, 1)\n",
    "# #         x = self.fc(x)\n",
    "#         x = F.avg_pool2d(x, x.size()[3])\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.linear(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "net = ResNet(BasicBlock, [9, 9, 9])\n",
    "print(net)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "decay_epoch = [100, 150]\n",
    "step_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "            Conv2d-3           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
      "            Conv2d-5           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
      "        BasicBlock-7           [-1, 16, 32, 32]               0\n",
      "            Conv2d-8           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-9           [-1, 16, 32, 32]              32\n",
      "           Conv2d-10           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-12           [-1, 16, 32, 32]               0\n",
      "           Conv2d-13           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-14           [-1, 16, 32, 32]              32\n",
      "           Conv2d-15           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-17           [-1, 16, 32, 32]               0\n",
      "           Conv2d-18           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 16, 32, 32]              32\n",
      "           Conv2d-20           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-21           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-22           [-1, 16, 32, 32]               0\n",
      "           Conv2d-23           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-24           [-1, 16, 32, 32]              32\n",
      "           Conv2d-25           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-26           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-27           [-1, 16, 32, 32]               0\n",
      "           Conv2d-28           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-29           [-1, 16, 32, 32]              32\n",
      "           Conv2d-30           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-31           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-32           [-1, 16, 32, 32]               0\n",
      "           Conv2d-33           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-34           [-1, 16, 32, 32]              32\n",
      "           Conv2d-35           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-36           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-37           [-1, 16, 32, 32]               0\n",
      "           Conv2d-38           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-39           [-1, 16, 32, 32]              32\n",
      "           Conv2d-40           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-41           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-42           [-1, 16, 32, 32]               0\n",
      "           Conv2d-43           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-44           [-1, 16, 32, 32]              32\n",
      "           Conv2d-45           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-46           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-47           [-1, 16, 32, 32]               0\n",
      "           Conv2d-48           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-49           [-1, 32, 16, 16]              64\n",
      "           Conv2d-50           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-51           [-1, 32, 16, 16]              64\n",
      "           Conv2d-52           [-1, 32, 16, 16]             512\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-56           [-1, 32, 16, 16]              64\n",
      "           Conv2d-57           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-58           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-59           [-1, 32, 16, 16]               0\n",
      "           Conv2d-60           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-61           [-1, 32, 16, 16]              64\n",
      "           Conv2d-62           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-63           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-64           [-1, 32, 16, 16]               0\n",
      "           Conv2d-65           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-66           [-1, 32, 16, 16]              64\n",
      "           Conv2d-67           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-68           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-69           [-1, 32, 16, 16]               0\n",
      "           Conv2d-70           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-71           [-1, 32, 16, 16]              64\n",
      "           Conv2d-72           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-73           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-74           [-1, 32, 16, 16]               0\n",
      "           Conv2d-75           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-76           [-1, 32, 16, 16]              64\n",
      "           Conv2d-77           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-78           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-79           [-1, 32, 16, 16]               0\n",
      "           Conv2d-80           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-81           [-1, 32, 16, 16]              64\n",
      "           Conv2d-82           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-83           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-84           [-1, 32, 16, 16]               0\n",
      "           Conv2d-85           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-86           [-1, 32, 16, 16]              64\n",
      "           Conv2d-87           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-88           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-89           [-1, 32, 16, 16]               0\n",
      "           Conv2d-90           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-91           [-1, 32, 16, 16]              64\n",
      "           Conv2d-92           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-93           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-94           [-1, 32, 16, 16]               0\n",
      "           Conv2d-95             [-1, 64, 8, 8]          18,432\n",
      "      BatchNorm2d-96             [-1, 64, 8, 8]             128\n",
      "           Conv2d-97             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 64, 8, 8]             128\n",
      "           Conv2d-99             [-1, 64, 8, 8]           2,048\n",
      "     BatchNorm2d-100             [-1, 64, 8, 8]             128\n",
      "      BasicBlock-101             [-1, 64, 8, 8]               0\n",
      "          Conv2d-102             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-103             [-1, 64, 8, 8]             128\n",
      "          Conv2d-104             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-105             [-1, 64, 8, 8]             128\n",
      "      BasicBlock-106             [-1, 64, 8, 8]               0\n",
      "          Conv2d-107             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-108             [-1, 64, 8, 8]             128\n",
      "          Conv2d-109             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-110             [-1, 64, 8, 8]             128\n",
      "      BasicBlock-111             [-1, 64, 8, 8]               0\n",
      "          Conv2d-112             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-113             [-1, 64, 8, 8]             128\n",
      "          Conv2d-114             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-115             [-1, 64, 8, 8]             128\n",
      "      BasicBlock-116             [-1, 64, 8, 8]               0\n",
      "          Conv2d-117             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-118             [-1, 64, 8, 8]             128\n",
      "          Conv2d-119             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-120             [-1, 64, 8, 8]             128\n",
      "      BasicBlock-121             [-1, 64, 8, 8]               0\n",
      "          Conv2d-122             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-123             [-1, 64, 8, 8]             128\n",
      "          Conv2d-124             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-125             [-1, 64, 8, 8]             128\n",
      "      BasicBlock-126             [-1, 64, 8, 8]               0\n",
      "          Conv2d-127             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-128             [-1, 64, 8, 8]             128\n",
      "          Conv2d-129             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-130             [-1, 64, 8, 8]             128\n",
      "      BasicBlock-131             [-1, 64, 8, 8]               0\n",
      "          Conv2d-132             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-133             [-1, 64, 8, 8]             128\n",
      "          Conv2d-134             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-135             [-1, 64, 8, 8]             128\n",
      "      BasicBlock-136             [-1, 64, 8, 8]               0\n",
      "          Conv2d-137             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-138             [-1, 64, 8, 8]             128\n",
      "          Conv2d-139             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-140             [-1, 64, 8, 8]             128\n",
      "      BasicBlock-141             [-1, 64, 8, 8]               0\n",
      "          Linear-142                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 855,770\n",
      "Trainable params: 855,770\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 10.28\n",
      "Params size (MB): 3.26\n",
      "Estimated Total Size (MB): 13.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary(net,(3,32,32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hing\n",
      "epoch :     1 loss : 2.7055011\n",
      "Accuracy of the network on the 10000 test images: 16 %\n",
      "epoch :     2 loss : 2.1457813\n",
      "Accuracy of the network on the 10000 test images: 26 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-548ba710d03d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print('hing')\n",
    "for epoch in range(30):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    #print(epoch)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # [inputs, labels]의 목록인 data로부터 입력을 받은 후;\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        #print(i)\n",
    "        # 변화도(Gradient) 매개변수를 0으로 만들고\n",
    "        \n",
    "\n",
    "        # 순전파 + 역전파 + 최적화를 한 후\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 통계를 출력합니다.\n",
    "        running_loss += loss.item()\n",
    "                  \n",
    "    step_lr_scheduler.step()\n",
    "    print('epoch : %5d loss : %.7f' %(epoch + 1, (running_loss / 65)))\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    #net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels =  data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../model/resNetCIFAR10nobias.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
