{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import torch.nn.init as init\n",
    "import time\n",
    "\n",
    "### parameter ###\n",
    "batchSize = 64\n",
    "setEpoch = 300\n",
    "### parameter ###\n",
    "\n",
    "### dataset ###\n",
    "\n",
    "#Set normalizer\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "#Set transform function\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "# transform_train = transforms.Compose(\n",
    "#     [transforms.RandomCrop(32),\n",
    "#      transforms.RandomHorizontalFlip(),\n",
    "#      transforms.ToTensor(),\n",
    "#      normalize])\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "\n",
    "#set dataset  \n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "#set loader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize,\n",
    "                                          shuffle=True, num_workers=2, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize,\n",
    "                                         shuffle=False, num_workers=2,pin_memory=True)\n",
    "#set class label on dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define NN\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class basicBlock(nn.Module):\n",
    "    def __init__(self, inChannel, growthRate, layerDepth, dropRate = 0.2):\n",
    "        super(basicBlock, self).__init__()\n",
    "        self.layerDepth = layerDepth\n",
    "        layers = []\n",
    "        for i in range(layerDepth):\n",
    "            layers.append(nn.BatchNorm2d(inChannel))\n",
    "            # 1x1 conv\n",
    "            layers.append(nn.Conv2d(inChannel, 4*growthRate, kernel_size=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(4*growthRate))\n",
    "            # 3x3 conv\n",
    "            layers.append(nn.Conv2d(4*growthRate, growthRate, kernel_size=3, padding = 1, bias=False))\n",
    "            inChannel += growthRate\n",
    "            \n",
    "        self.moduleList = nn.ModuleList(layers)\n",
    "        self.dropRate = dropRate\n",
    "    def forward(self, x):\n",
    "        for i in range(self.layerDepth):\n",
    "            #BN, ReLU\n",
    "            out = F.relu(self.moduleList[4*i](x))\n",
    "            #1x1 conv (bottleNeck)\n",
    "            out = self.moduleList[4*i + 1](out)\n",
    "            #BN, ReLU\n",
    "            out = F.relu(self.moduleList[4*i + 2](out))\n",
    "            #3x3 conv\n",
    "            out = self.moduleList[4*i + 3](out)    \n",
    "            #dropout\n",
    "            out = F.dropout(out, p = self.dropRate , training=self.training)\n",
    "            #concatation\n",
    "            x = torch.cat((x,out),dim=1)\n",
    "        return x\n",
    "\n",
    "class upNet(nn.Conv2d):\n",
    "    def __init__(self):\n",
    "        \n",
    "    def forward(self, scale, outchannel):\n",
    "        \n",
    "class RDB(nn.Module):\n",
    "    def __init__(self, inChannel, growthRate, layerDepth):\n",
    "        layer = []\n",
    "        self.layerDepth = layerDepth\n",
    "        outChannel = inChannel\n",
    "        for i in range(layerDepth):\n",
    "            # 3x3 conv\n",
    "            layers.append(nn.Conv2d(inChannel, growthRate, kernel_size=3, padding = 1, bias=False))\n",
    "            inChannel += growthRate\n",
    "        self.rdbLayers = nn.ModuleList(layers)\n",
    "        #local feature fusion\n",
    "        self.conv1x1=nn.Conv2d(inChannel, outChannel)\n",
    "    def forward(self, x)\n",
    "        localRes = x\n",
    "        for i in range(self.layerDepth):\n",
    "            out = self.moduleList[i](x)\n",
    "            out = nn.relu(out)\n",
    "            x = torch.cat((x,out),dim=1)\n",
    "        \n",
    "        x = localRes + x\n",
    "        return x\n",
    "    \n",
    "class RDN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(denseNet, self).__init__()\n",
    "        #parameter\n",
    "        self.inChannel = 24\n",
    "        self.growthRate = 64\n",
    "        self.blockDepth = 16\n",
    "        self.convDepth = 8\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(self.blockDepth):\n",
    "            layers.append = RDB(inChannel, growthRate, convDepth)\n",
    "        self.rdbs = nn.ModuleList(layers)\n",
    "            \n",
    "#         self.conv0 = nn.Conv2d(3, self.inChannel , kernel_size=3, padding = 1, bias = False)\n",
    "        \n",
    "#         #transicion layer\n",
    "#         TLdepth1 = self.inChannel + (self.growthRate)*self.layerDepth\n",
    "#         self.TLbn1 = (nn.BatchNorm2d(TLdepth1))\n",
    "#         self.convTL1  = nn.Conv2d(TLdepth1, self._theta(TLdepth1), kernel_size = 1, bias = False)\n",
    "#         self.avgPool1 = nn.AvgPool2d(2, stride = 2)\n",
    "        \n",
    "#         TLdepth2 = self._theta(TLdepth1) + (self.growthRate)*self.layerDepth\n",
    "#         self.TLbn2 = (nn.BatchNorm2d(TLdepth2))\n",
    "#         self.convTL2  = nn.Conv2d(TLdepth2, self._theta(TLdepth2), kernel_size = 1, bias = False)\n",
    "#         self.avgPool2 = nn.AvgPool2d(2, stride = 2)\n",
    "        \n",
    "#         #dense blk\n",
    "#         #when cifar, layer's depth are same\n",
    "#         self.dense1 = basicBlock(self.inChannel, self.growthRate, self.layerDepth)\n",
    "#         self.dense2 = basicBlock(self._theta(TLdepth1), self.growthRate, self.layerDepth)\n",
    "#         self.dense3 =  basicBlock(self._theta(TLdepth2), self.growthRate, self.layerDepth)\n",
    "        \n",
    "#         #classification Layer\n",
    "#         depthClass = self._theta(TLdepth2) +  (self.growthRate)*self.layerDepth\n",
    "#         self.GlobalAvgPool = nn.AvgPool2d(8, stride = 1)\n",
    "#         self.linear = nn.Linear(depthClass, 10)\n",
    "        \n",
    "        \n",
    "#         self.apply(_weights_init)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #SFENet\n",
    "        x = self.sfe1(x)\n",
    "        out = self.sfe2(x)\n",
    "        #RDBs\n",
    "        out = self.rdbs(out)\n",
    "        #DFF\n",
    "        out = self.gff(out)\n",
    "        x = x + out\n",
    "        #UPNet\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
