{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import torch.nn.init as init\n",
    "import time\n",
    "\n",
    "### parameter ###\n",
    "batchSize = 64\n",
    "setEpoch = 300\n",
    "### parameter ###\n",
    "\n",
    "### dataset ###\n",
    "\n",
    "#Set normalizer\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "#Set transform function\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "# transform_train = transforms.Compose(\n",
    "#     [transforms.RandomCrop(32),\n",
    "#      transforms.RandomHorizontalFlip(),\n",
    "#      transforms.ToTensor(),\n",
    "#      normalize])\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "\n",
    "#set dataset  \n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "#set loader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize,\n",
    "                                          shuffle=True, num_workers=2, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize,\n",
    "                                         shuffle=False, num_workers=2,pin_memory=True)\n",
    "#set class label on dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define NN\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class basicBlock(nn.Module):\n",
    "    def __init__(self, inChannel, growthRate, layerDepth, dropRate = 0.2):\n",
    "        super(basicBlock, self).__init__()\n",
    "        self.layerDepth = layerDepth\n",
    "        layers = []\n",
    "        for i in range(layerDepth):\n",
    "            layers.append(nn.BatchNorm2d(inChannel))\n",
    "            # 1x1 conv\n",
    "            layers.append(nn.Conv2d(inChannel, 4*growthRate, kernel_size=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(4*growthRate))\n",
    "            # 3x3 conv\n",
    "            layers.append(nn.Conv2d(4*growthRate, growthRate, kernel_size=3, padding = 1, bias=False))\n",
    "            inChannel += growthRate\n",
    "            \n",
    "        self.moduleList = nn.ModuleList(layers)\n",
    "        self.dropRate = dropRate\n",
    "    def forward(self, x):\n",
    "        for i in range(self.layerDepth):\n",
    "            #BN, ReLU\n",
    "            out = F.relu(self.moduleList[4*i](x))\n",
    "            #1x1 conv (bottleNeck)\n",
    "            out = self.moduleList[4*i + 1](out)\n",
    "            #BN, ReLU\n",
    "            out = F.relu(self.moduleList[4*i + 2](out))\n",
    "            #3x3 conv\n",
    "            out = self.moduleList[4*i + 3](out)    \n",
    "            #dropout\n",
    "            out = F.dropout(out, p = self.dropRate , training=self.training)\n",
    "            #concatation\n",
    "            x = torch.cat((x,out),dim=1)\n",
    "        return x\n",
    "\n",
    "class denseNet(nn.Module):\n",
    "    def _theta(self,layerDepth):\n",
    "        return int(layerDepth*self.theta)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(denseNet, self).__init__()\n",
    "        #parameter\n",
    "        self.inChannel = 24\n",
    "        self.growthRate = 12\n",
    "        self.layerDepth = 16\n",
    "        self.theta = 0.5 \n",
    "        \n",
    "        self.conv0 = nn.Conv2d(3, self.inChannel , kernel_size=3, padding = 1, bias = False)\n",
    "        \n",
    "        #transicion layer\n",
    "        TLdepth1 = self.inChannel + (self.growthRate)*self.layerDepth\n",
    "        self.TLbn1 = (nn.BatchNorm2d(TLdepth1))\n",
    "        self.convTL1  = nn.Conv2d(TLdepth1, self._theta(TLdepth1), kernel_size = 1, bias = False)\n",
    "        self.avgPool1 = nn.AvgPool2d(2, stride = 2)\n",
    "        \n",
    "        TLdepth2 = self._theta(TLdepth1) + (self.growthRate)*self.layerDepth\n",
    "        self.TLbn2 = (nn.BatchNorm2d(TLdepth2))\n",
    "        self.convTL2  = nn.Conv2d(TLdepth2, self._theta(TLdepth2), kernel_size = 1, bias = False)\n",
    "        self.avgPool2 = nn.AvgPool2d(2, stride = 2)\n",
    "        \n",
    "        #dense blk\n",
    "        #when cifar, layer's depth are same\n",
    "        self.dense1 = basicBlock(self.inChannel, self.growthRate, self.layerDepth)\n",
    "        self.dense2 = basicBlock(self._theta(TLdepth1), self.growthRate, self.layerDepth)\n",
    "        self.dense3 =  basicBlock(self._theta(TLdepth2), self.growthRate, self.layerDepth)\n",
    "        \n",
    "        #classification Layer\n",
    "        depthClass = self._theta(TLdepth2) +  (self.growthRate)*self.layerDepth\n",
    "        self.GlobalAvgPool = nn.AvgPool2d(8, stride = 1)\n",
    "        self.linear = nn.Linear(depthClass, 10)\n",
    "        \n",
    "        \n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #conv\n",
    "        x = self.conv0(x)\n",
    "        \n",
    "        #dense blk 1\n",
    "        x = self.dense1(x)\n",
    "        #TL - BL -> ReLu -> Conv -> AvgPool \n",
    "        x = self.avgPool1(self.convTL1(F.relu(self.TLbn1(x))))\n",
    "        \n",
    "        #dense blk 2\n",
    "        x = self.dense2(x)\n",
    "        #TL - BL -> ReLu -> Conv -> AvgPool\n",
    "        x = self.avgPool2(self.convTL2(F.relu(self.TLbn2(x))))\n",
    "        \n",
    "        #dense blk 3\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        #fc\n",
    "        x = self.GlobalAvgPool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "            Conv2d-3           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-4           [-1, 48, 32, 32]              96\n",
      "            Conv2d-5           [-1, 12, 32, 32]           5,184\n",
      "       BatchNorm2d-6           [-1, 36, 32, 32]              72\n",
      "            Conv2d-7           [-1, 48, 32, 32]           1,728\n",
      "       BatchNorm2d-8           [-1, 48, 32, 32]              96\n",
      "            Conv2d-9           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-10           [-1, 48, 32, 32]              96\n",
      "           Conv2d-11           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "           Conv2d-13           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-14           [-1, 60, 32, 32]             120\n",
      "           Conv2d-15           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "           Conv2d-17           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-18           [-1, 72, 32, 32]             144\n",
      "           Conv2d-19           [-1, 48, 32, 32]           3,456\n",
      "      BatchNorm2d-20           [-1, 48, 32, 32]              96\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-22           [-1, 84, 32, 32]             168\n",
      "           Conv2d-23           [-1, 48, 32, 32]           4,032\n",
      "      BatchNorm2d-24           [-1, 48, 32, 32]              96\n",
      "           Conv2d-25           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-26           [-1, 96, 32, 32]             192\n",
      "           Conv2d-27           [-1, 48, 32, 32]           4,608\n",
      "      BatchNorm2d-28           [-1, 48, 32, 32]              96\n",
      "           Conv2d-29           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-30          [-1, 108, 32, 32]             216\n",
      "           Conv2d-31           [-1, 48, 32, 32]           5,184\n",
      "      BatchNorm2d-32           [-1, 48, 32, 32]              96\n",
      "           Conv2d-33           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-34          [-1, 120, 32, 32]             240\n",
      "           Conv2d-35           [-1, 48, 32, 32]           5,760\n",
      "      BatchNorm2d-36           [-1, 48, 32, 32]              96\n",
      "           Conv2d-37           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-38          [-1, 132, 32, 32]             264\n",
      "           Conv2d-39           [-1, 48, 32, 32]           6,336\n",
      "      BatchNorm2d-40           [-1, 48, 32, 32]              96\n",
      "           Conv2d-41           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-42          [-1, 144, 32, 32]             288\n",
      "           Conv2d-43           [-1, 48, 32, 32]           6,912\n",
      "      BatchNorm2d-44           [-1, 48, 32, 32]              96\n",
      "           Conv2d-45           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-46          [-1, 156, 32, 32]             312\n",
      "           Conv2d-47           [-1, 48, 32, 32]           7,488\n",
      "      BatchNorm2d-48           [-1, 48, 32, 32]              96\n",
      "           Conv2d-49           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-50          [-1, 168, 32, 32]             336\n",
      "           Conv2d-51           [-1, 48, 32, 32]           8,064\n",
      "      BatchNorm2d-52           [-1, 48, 32, 32]              96\n",
      "           Conv2d-53           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-54          [-1, 180, 32, 32]             360\n",
      "           Conv2d-55           [-1, 48, 32, 32]           8,640\n",
      "      BatchNorm2d-56           [-1, 48, 32, 32]              96\n",
      "           Conv2d-57           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-58          [-1, 192, 32, 32]             384\n",
      "           Conv2d-59           [-1, 48, 32, 32]           9,216\n",
      "      BatchNorm2d-60           [-1, 48, 32, 32]              96\n",
      "           Conv2d-61           [-1, 12, 32, 32]           5,184\n",
      "      BatchNorm2d-62          [-1, 204, 32, 32]             408\n",
      "           Conv2d-63           [-1, 48, 32, 32]           9,792\n",
      "      BatchNorm2d-64           [-1, 48, 32, 32]              96\n",
      "           Conv2d-65           [-1, 12, 32, 32]           5,184\n",
      "       basicBlock-66          [-1, 216, 32, 32]               0\n",
      "      BatchNorm2d-67          [-1, 216, 32, 32]             432\n",
      "           Conv2d-68          [-1, 108, 32, 32]          23,328\n",
      "        AvgPool2d-69          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-70          [-1, 108, 16, 16]             216\n",
      "           Conv2d-71           [-1, 48, 16, 16]           5,184\n",
      "      BatchNorm2d-72           [-1, 48, 16, 16]              96\n",
      "           Conv2d-73           [-1, 12, 16, 16]           5,184\n",
      "      BatchNorm2d-74          [-1, 120, 16, 16]             240\n",
      "           Conv2d-75           [-1, 48, 16, 16]           5,760\n",
      "      BatchNorm2d-76           [-1, 48, 16, 16]              96\n",
      "           Conv2d-77           [-1, 12, 16, 16]           5,184\n",
      "      BatchNorm2d-78          [-1, 132, 16, 16]             264\n",
      "           Conv2d-79           [-1, 48, 16, 16]           6,336\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "           Conv2d-81           [-1, 12, 16, 16]           5,184\n",
      "      BatchNorm2d-82          [-1, 144, 16, 16]             288\n",
      "           Conv2d-83           [-1, 48, 16, 16]           6,912\n",
      "      BatchNorm2d-84           [-1, 48, 16, 16]              96\n",
      "           Conv2d-85           [-1, 12, 16, 16]           5,184\n",
      "      BatchNorm2d-86          [-1, 156, 16, 16]             312\n",
      "           Conv2d-87           [-1, 48, 16, 16]           7,488\n",
      "      BatchNorm2d-88           [-1, 48, 16, 16]              96\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "      BatchNorm2d-90          [-1, 168, 16, 16]             336\n",
      "           Conv2d-91           [-1, 48, 16, 16]           8,064\n",
      "      BatchNorm2d-92           [-1, 48, 16, 16]              96\n",
      "           Conv2d-93           [-1, 12, 16, 16]           5,184\n",
      "      BatchNorm2d-94          [-1, 180, 16, 16]             360\n",
      "           Conv2d-95           [-1, 48, 16, 16]           8,640\n",
      "      BatchNorm2d-96           [-1, 48, 16, 16]              96\n",
      "           Conv2d-97           [-1, 12, 16, 16]           5,184\n",
      "      BatchNorm2d-98          [-1, 192, 16, 16]             384\n",
      "           Conv2d-99           [-1, 48, 16, 16]           9,216\n",
      "     BatchNorm2d-100           [-1, 48, 16, 16]              96\n",
      "          Conv2d-101           [-1, 12, 16, 16]           5,184\n",
      "     BatchNorm2d-102          [-1, 204, 16, 16]             408\n",
      "          Conv2d-103           [-1, 48, 16, 16]           9,792\n",
      "     BatchNorm2d-104           [-1, 48, 16, 16]              96\n",
      "          Conv2d-105           [-1, 12, 16, 16]           5,184\n",
      "     BatchNorm2d-106          [-1, 216, 16, 16]             432\n",
      "          Conv2d-107           [-1, 48, 16, 16]          10,368\n",
      "     BatchNorm2d-108           [-1, 48, 16, 16]              96\n",
      "          Conv2d-109           [-1, 12, 16, 16]           5,184\n",
      "     BatchNorm2d-110          [-1, 228, 16, 16]             456\n",
      "          Conv2d-111           [-1, 48, 16, 16]          10,944\n",
      "     BatchNorm2d-112           [-1, 48, 16, 16]              96\n",
      "          Conv2d-113           [-1, 12, 16, 16]           5,184\n",
      "     BatchNorm2d-114          [-1, 240, 16, 16]             480\n",
      "          Conv2d-115           [-1, 48, 16, 16]          11,520\n",
      "     BatchNorm2d-116           [-1, 48, 16, 16]              96\n",
      "          Conv2d-117           [-1, 12, 16, 16]           5,184\n",
      "     BatchNorm2d-118          [-1, 252, 16, 16]             504\n",
      "          Conv2d-119           [-1, 48, 16, 16]          12,096\n",
      "     BatchNorm2d-120           [-1, 48, 16, 16]              96\n",
      "          Conv2d-121           [-1, 12, 16, 16]           5,184\n",
      "     BatchNorm2d-122          [-1, 264, 16, 16]             528\n",
      "          Conv2d-123           [-1, 48, 16, 16]          12,672\n",
      "     BatchNorm2d-124           [-1, 48, 16, 16]              96\n",
      "          Conv2d-125           [-1, 12, 16, 16]           5,184\n",
      "     BatchNorm2d-126          [-1, 276, 16, 16]             552\n",
      "          Conv2d-127           [-1, 48, 16, 16]          13,248\n",
      "     BatchNorm2d-128           [-1, 48, 16, 16]              96\n",
      "          Conv2d-129           [-1, 12, 16, 16]           5,184\n",
      "     BatchNorm2d-130          [-1, 288, 16, 16]             576\n",
      "          Conv2d-131           [-1, 48, 16, 16]          13,824\n",
      "     BatchNorm2d-132           [-1, 48, 16, 16]              96\n",
      "          Conv2d-133           [-1, 12, 16, 16]           5,184\n",
      "      basicBlock-134          [-1, 300, 16, 16]               0\n",
      "     BatchNorm2d-135          [-1, 300, 16, 16]             600\n",
      "          Conv2d-136          [-1, 150, 16, 16]          45,000\n",
      "       AvgPool2d-137            [-1, 150, 8, 8]               0\n",
      "     BatchNorm2d-138            [-1, 150, 8, 8]             300\n",
      "          Conv2d-139             [-1, 48, 8, 8]           7,200\n",
      "     BatchNorm2d-140             [-1, 48, 8, 8]              96\n",
      "          Conv2d-141             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-142            [-1, 162, 8, 8]             324\n",
      "          Conv2d-143             [-1, 48, 8, 8]           7,776\n",
      "     BatchNorm2d-144             [-1, 48, 8, 8]              96\n",
      "          Conv2d-145             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-146            [-1, 174, 8, 8]             348\n",
      "          Conv2d-147             [-1, 48, 8, 8]           8,352\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "          Conv2d-149             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-150            [-1, 186, 8, 8]             372\n",
      "          Conv2d-151             [-1, 48, 8, 8]           8,928\n",
      "     BatchNorm2d-152             [-1, 48, 8, 8]              96\n",
      "          Conv2d-153             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-154            [-1, 198, 8, 8]             396\n",
      "          Conv2d-155             [-1, 48, 8, 8]           9,504\n",
      "     BatchNorm2d-156             [-1, 48, 8, 8]              96\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-158            [-1, 210, 8, 8]             420\n",
      "          Conv2d-159             [-1, 48, 8, 8]          10,080\n",
      "     BatchNorm2d-160             [-1, 48, 8, 8]              96\n",
      "          Conv2d-161             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-162            [-1, 222, 8, 8]             444\n",
      "          Conv2d-163             [-1, 48, 8, 8]          10,656\n",
      "     BatchNorm2d-164             [-1, 48, 8, 8]              96\n",
      "          Conv2d-165             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-166            [-1, 234, 8, 8]             468\n",
      "          Conv2d-167             [-1, 48, 8, 8]          11,232\n",
      "     BatchNorm2d-168             [-1, 48, 8, 8]              96\n",
      "          Conv2d-169             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-170            [-1, 246, 8, 8]             492\n",
      "          Conv2d-171             [-1, 48, 8, 8]          11,808\n",
      "     BatchNorm2d-172             [-1, 48, 8, 8]              96\n",
      "          Conv2d-173             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-174            [-1, 258, 8, 8]             516\n",
      "          Conv2d-175             [-1, 48, 8, 8]          12,384\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "          Conv2d-177             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-178            [-1, 270, 8, 8]             540\n",
      "          Conv2d-179             [-1, 48, 8, 8]          12,960\n",
      "     BatchNorm2d-180             [-1, 48, 8, 8]              96\n",
      "          Conv2d-181             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-182            [-1, 282, 8, 8]             564\n",
      "          Conv2d-183             [-1, 48, 8, 8]          13,536\n",
      "     BatchNorm2d-184             [-1, 48, 8, 8]              96\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-186            [-1, 294, 8, 8]             588\n",
      "          Conv2d-187             [-1, 48, 8, 8]          14,112\n",
      "     BatchNorm2d-188             [-1, 48, 8, 8]              96\n",
      "          Conv2d-189             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-190            [-1, 306, 8, 8]             612\n",
      "          Conv2d-191             [-1, 48, 8, 8]          14,688\n",
      "     BatchNorm2d-192             [-1, 48, 8, 8]              96\n",
      "          Conv2d-193             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-194            [-1, 318, 8, 8]             636\n",
      "          Conv2d-195             [-1, 48, 8, 8]          15,264\n",
      "     BatchNorm2d-196             [-1, 48, 8, 8]              96\n",
      "          Conv2d-197             [-1, 12, 8, 8]           5,184\n",
      "     BatchNorm2d-198            [-1, 330, 8, 8]             660\n",
      "          Conv2d-199             [-1, 48, 8, 8]          15,840\n",
      "     BatchNorm2d-200             [-1, 48, 8, 8]              96\n",
      "          Conv2d-201             [-1, 12, 8, 8]           5,184\n",
      "      basicBlock-202            [-1, 342, 8, 8]               0\n",
      "       AvgPool2d-203            [-1, 342, 1, 1]               0\n",
      "          Linear-204                   [-1, 10]           3,430\n",
      "================================================================\n",
      "Total params: 768,478\n",
      "Trainable params: 768,478\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 46.36\n",
      "Params size (MB): 2.93\n",
      "Estimated Total Size (MB): 49.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = denseNet()\n",
    "device = torch.device(\"cuda:0\")\n",
    "net.to(device)\n",
    "summary(net,(3,32,32))\n",
    "#use cuda instead cpu \n",
    "\n",
    "#loss function \n",
    "criterion = nn.L1Loss()\n",
    "#optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "#eopch 100 -> lr = 0.01, epoch 150 -> lr = 0.001\n",
    "decay_epoch = [int(setEpoch/2), int(3*setEpoch/4)]\n",
    "step_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denseNet(\n",
      "  (conv0): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (TLbn1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (convTL1): Conv2d(216, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (avgPool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (TLbn2): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (convTL2): Conv2d(300, 150, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (avgPool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (dense1): basicBlock(\n",
      "    (moduleList): ModuleList(\n",
      "      (0): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (12): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (13): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (14): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (15): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (16): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (17): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (18): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (22): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (23): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (24): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (25): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (26): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (27): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (28): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (29): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (30): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (31): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (32): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (33): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (34): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (35): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (36): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (37): Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (38): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (39): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (40): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (41): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (42): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (43): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (44): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (45): Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (46): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (47): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (48): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (49): Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (50): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (51): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (52): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (53): Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (54): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (55): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (56): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (57): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (58): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (59): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (60): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (61): Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (62): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (63): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (dense2): basicBlock(\n",
      "    (moduleList): ModuleList(\n",
      "      (0): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (12): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (13): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (14): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (15): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (16): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (17): Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (18): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (22): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (23): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (24): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (25): Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (26): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (27): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (28): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (29): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (30): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (31): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (32): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (33): Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (34): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (35): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (36): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (37): Conv2d(216, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (38): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (39): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (40): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (41): Conv2d(228, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (42): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (43): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (44): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (45): Conv2d(240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (46): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (47): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (48): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (49): Conv2d(252, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (50): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (51): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (52): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (53): Conv2d(264, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (54): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (55): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (56): BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (57): Conv2d(276, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (58): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (59): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (60): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (61): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (62): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (63): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (dense3): basicBlock(\n",
      "    (moduleList): ModuleList(\n",
      "      (0): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Conv2d(150, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Conv2d(162, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): Conv2d(174, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (12): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (13): Conv2d(186, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (14): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (15): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (16): BatchNorm2d(198, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (17): Conv2d(198, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (18): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(210, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): Conv2d(210, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (22): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (23): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (24): BatchNorm2d(222, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (25): Conv2d(222, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (26): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (27): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (28): BatchNorm2d(234, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (29): Conv2d(234, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (30): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (31): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (32): BatchNorm2d(246, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (33): Conv2d(246, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (34): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (35): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (36): BatchNorm2d(258, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (37): Conv2d(258, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (38): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (39): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (40): BatchNorm2d(270, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (41): Conv2d(270, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (42): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (43): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (44): BatchNorm2d(282, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (45): Conv2d(282, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (46): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (47): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (48): BatchNorm2d(294, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (49): Conv2d(294, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (50): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (51): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (52): BatchNorm2d(306, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (53): Conv2d(306, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (54): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (55): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (56): BatchNorm2d(318, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (57): Conv2d(318, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (58): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (59): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (60): BatchNorm2d(330, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (61): Conv2d(330, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (62): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (63): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (GlobalAvgPool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (linear): Linear(in_features=342, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print all layer of NN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hing\n",
      "epoch :     1 time: 87.7571 loss : 1.6317173\n",
      "Accuracy of the network on the 10000 test images: 50 %\n",
      "epoch :     2 time: 84.2863 loss : 1.0881300\n",
      "Accuracy of the network on the 10000 test images: 63 %\n",
      "epoch :     3 time: 85.0697 loss : 0.8345923\n",
      "Accuracy of the network on the 10000 test images: 68 %\n",
      "epoch :     4 time: 86.2856 loss : 0.6924507\n",
      "Accuracy of the network on the 10000 test images: 68 %\n",
      "epoch :     5 time: 86.3886 loss : 0.6040313\n",
      "Accuracy of the network on the 10000 test images: 75 %\n",
      "epoch :     6 time: 83.4322 loss : 0.5404195\n",
      "Accuracy of the network on the 10000 test images: 82 %\n",
      "epoch :     7 time: 86.1806 loss : 0.5017599\n",
      "Accuracy of the network on the 10000 test images: 81 %\n",
      "epoch :     8 time: 84.9636 loss : 0.4613418\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :     9 time: 85.2541 loss : 0.4380511\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :    10 time: 85.1772 loss : 0.4256793\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :    11 time: 86.1984 loss : 0.3909137\n",
      "Accuracy of the network on the 10000 test images: 82 %\n",
      "epoch :    12 time: 84.7505 loss : 0.3783312\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    13 time: 86.3889 loss : 0.3652836\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    14 time: 85.8244 loss : 0.3517694\n",
      "Accuracy of the network on the 10000 test images: 78 %\n",
      "epoch :    15 time: 85.0517 loss : 0.3468472\n",
      "Accuracy of the network on the 10000 test images: 82 %\n",
      "epoch :    16 time: 85.9703 loss : 0.3315217\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    17 time: 85.0012 loss : 0.3346403\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    18 time: 86.8126 loss : 0.3161827\n",
      "Accuracy of the network on the 10000 test images: 79 %\n",
      "epoch :    19 time: 86.5586 loss : 0.3169148\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    20 time: 86.3914 loss : 0.3081787\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    21 time: 86.3495 loss : 0.3058416\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :    22 time: 85.3503 loss : 0.3021563\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    23 time: 85.7824 loss : 0.2992987\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    24 time: 84.1413 loss : 0.2940388\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    25 time: 84.3256 loss : 0.2893914\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :    26 time: 84.1126 loss : 0.2860460\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :    27 time: 84.6514 loss : 0.2883430\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    28 time: 86.2590 loss : 0.2847794\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    29 time: 85.6952 loss : 0.2759106\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    30 time: 85.2472 loss : 0.2736165\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    31 time: 84.8481 loss : 0.2709032\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :    32 time: 85.4039 loss : 0.2661740\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    33 time: 85.6065 loss : 0.2676358\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :    34 time: 84.5307 loss : 0.2672437\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    35 time: 86.2535 loss : 0.2612041\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :    36 time: 84.2412 loss : 0.2585114\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    37 time: 84.2357 loss : 0.2563986\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    38 time: 87.1268 loss : 0.2586082\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    39 time: 83.3515 loss : 0.2598134\n",
      "Accuracy of the network on the 10000 test images: 82 %\n",
      "epoch :    40 time: 84.7693 loss : 0.2504666\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :    41 time: 84.7504 loss : 0.2530687\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    42 time: 87.1469 loss : 0.2465978\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    43 time: 86.8776 loss : 0.2463851\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    44 time: 85.6296 loss : 0.2471724\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :    45 time: 83.7796 loss : 0.2502838\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    46 time: 85.0974 loss : 0.2436024\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :    47 time: 85.1471 loss : 0.2537400\n",
      "Accuracy of the network on the 10000 test images: 82 %\n",
      "epoch :    48 time: 86.4033 loss : 0.2414577\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :    49 time: 83.9705 loss : 0.2349319\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    50 time: 85.1564 loss : 0.2380801\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :    51 time: 86.8604 loss : 0.2373620\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    52 time: 84.4906 loss : 0.2428013\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :    53 time: 86.4630 loss : 0.2319768\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    54 time: 84.8313 loss : 0.2301551\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    55 time: 84.2768 loss : 0.2368694\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "epoch :    56 time: 85.7983 loss : 0.2337539\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :    57 time: 85.5812 loss : 0.2245433\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :    58 time: 86.2308 loss : 0.2281302\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    59 time: 85.1715 loss : 0.2298618\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    60 time: 85.1852 loss : 0.2349465\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    61 time: 84.8397 loss : 0.2251851\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :    62 time: 85.4788 loss : 0.2262688\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    63 time: 85.6573 loss : 0.2251781\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :    64 time: 84.5206 loss : 0.2256757\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "epoch :    65 time: 86.3036 loss : 0.2240739\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    66 time: 85.9724 loss : 0.2236197\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    67 time: 84.6940 loss : 0.2250197\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :    68 time: 85.0401 loss : 0.2160561\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    69 time: 85.6241 loss : 0.2208750\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    70 time: 84.7120 loss : 0.2251498\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :    71 time: 84.5667 loss : 0.2169491\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :    72 time: 85.8247 loss : 0.2192594\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :    73 time: 85.1600 loss : 0.2146795\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    74 time: 85.8541 loss : 0.2222941\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :    75 time: 84.8632 loss : 0.2119569\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    76 time: 85.2071 loss : 0.2182900\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "epoch :    77 time: 84.5050 loss : 0.2148638\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    78 time: 83.3288 loss : 0.2160971\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :    79 time: 86.1186 loss : 0.2173219\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    80 time: 85.9697 loss : 0.2107356\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    81 time: 84.2628 loss : 0.2162688\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    82 time: 84.5049 loss : 0.2069817\n",
      "Accuracy of the network on the 10000 test images: 88 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :    83 time: 86.0329 loss : 0.2058892\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    84 time: 85.8819 loss : 0.2109311\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    85 time: 85.2143 loss : 0.2143185\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    86 time: 84.9764 loss : 0.2159796\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :    87 time: 85.9978 loss : 0.2058173\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :    88 time: 85.9097 loss : 0.2123542\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    89 time: 83.9200 loss : 0.2125669\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :    90 time: 85.9038 loss : 0.2111684\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "epoch :    91 time: 86.1290 loss : 0.2078477\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    92 time: 85.9895 loss : 0.2113779\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :    93 time: 85.8297 loss : 0.2093002\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :    94 time: 85.4209 loss : 0.2156051\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    95 time: 87.1812 loss : 0.2082583\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    96 time: 85.4528 loss : 0.2118452\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :    97 time: 86.3012 loss : 0.2030980\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :    98 time: 86.7439 loss : 0.2023125\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :    99 time: 83.9608 loss : 0.2027710\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   100 time: 84.8636 loss : 0.2114761\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   101 time: 83.2553 loss : 0.2047402\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   102 time: 86.2243 loss : 0.2062008\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   103 time: 86.1824 loss : 0.2024850\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "epoch :   104 time: 85.3710 loss : 0.2030747\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :   105 time: 85.4333 loss : 0.2096460\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   106 time: 85.2718 loss : 0.2008660\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :   107 time: 85.7938 loss : 0.2015183\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :   108 time: 84.0045 loss : 0.2036208\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   109 time: 84.7292 loss : 0.2035229\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   110 time: 85.8415 loss : 0.2067763\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   111 time: 85.8241 loss : 0.2079847\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "epoch :   112 time: 85.6635 loss : 0.2019950\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   113 time: 85.1560 loss : 0.2034469\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   114 time: 85.3379 loss : 0.2059844\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :   115 time: 85.3925 loss : 0.1986875\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   116 time: 85.0007 loss : 0.2020365\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :   117 time: 85.2427 loss : 0.2076221\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   118 time: 85.2145 loss : 0.2004200\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :   119 time: 85.1824 loss : 0.2019734\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   120 time: 84.4608 loss : 0.2015224\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :   121 time: 85.0050 loss : 0.2052116\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   122 time: 84.4544 loss : 0.1966714\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   123 time: 85.1245 loss : 0.2006860\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "epoch :   124 time: 85.1025 loss : 0.1969400\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "epoch :   125 time: 85.5867 loss : 0.1985277\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   126 time: 85.9204 loss : 0.2013950\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   127 time: 84.7879 loss : 0.2002099\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   128 time: 85.2912 loss : 0.1968908\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   129 time: 86.5346 loss : 0.1944813\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   130 time: 87.2583 loss : 0.2044803\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   131 time: 85.6872 loss : 0.2061267\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   132 time: 85.4375 loss : 0.1984457\n",
      "Accuracy of the network on the 10000 test images: 78 %\n",
      "epoch :   133 time: 84.2350 loss : 0.1970873\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   134 time: 86.9061 loss : 0.2006309\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   135 time: 86.9813 loss : 0.2020621\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "epoch :   136 time: 85.2073 loss : 0.2026050\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "epoch :   137 time: 85.6076 loss : 0.1979980\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   138 time: 84.1171 loss : 0.1952909\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   139 time: 85.2560 loss : 0.2016180\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   140 time: 86.0070 loss : 0.1951088\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   141 time: 85.5816 loss : 0.2000817\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   142 time: 84.5934 loss : 0.1974406\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :   143 time: 86.1237 loss : 0.1906845\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   144 time: 85.4639 loss : 0.1941544\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "epoch :   145 time: 86.9804 loss : 0.1997182\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "epoch :   146 time: 85.5295 loss : 0.1929801\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   147 time: 83.6163 loss : 0.2038919\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "epoch :   148 time: 86.6728 loss : 0.2009063\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :   149 time: 85.3305 loss : 0.2040386\n",
      "Accuracy of the network on the 10000 test images: 86 %\n",
      "epoch :   150 time: 85.6831 loss : 0.1952262\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "epoch :   151 time: 85.5952 loss : 0.0782001\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   152 time: 86.0671 loss : 0.0474433\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   153 time: 86.7610 loss : 0.0356211\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   154 time: 85.3168 loss : 0.0282886\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   155 time: 87.1698 loss : 0.0242880\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   156 time: 85.7560 loss : 0.0189220\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   157 time: 85.2352 loss : 0.0184717\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   158 time: 84.6637 loss : 0.0151709\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   159 time: 88.0121 loss : 0.0145381\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   160 time: 86.2171 loss : 0.0131591\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   161 time: 86.0578 loss : 0.0133336\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   162 time: 84.9789 loss : 0.0113392\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   163 time: 84.5803 loss : 0.0111143\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   164 time: 85.0534 loss : 0.0088396\n",
      "Accuracy of the network on the 10000 test images: 93 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   165 time: 84.8333 loss : 0.0086240\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   166 time: 87.3734 loss : 0.0084265\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   167 time: 85.6382 loss : 0.0087326\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   168 time: 84.1306 loss : 0.0077897\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   169 time: 83.5521 loss : 0.0087147\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   170 time: 84.9014 loss : 0.0081743\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   171 time: 85.5647 loss : 0.0073723\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   172 time: 85.4390 loss : 0.0061324\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   173 time: 84.2050 loss : 0.0073091\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   174 time: 84.5824 loss : 0.0064653\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   175 time: 85.3090 loss : 0.0065431\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   176 time: 85.4709 loss : 0.0065401\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   177 time: 84.6786 loss : 0.0070146\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   178 time: 85.9527 loss : 0.0063972\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   179 time: 87.7820 loss : 0.0071960\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   180 time: 85.3508 loss : 0.0065174\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   181 time: 83.8575 loss : 0.0067573\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   182 time: 85.3013 loss : 0.0061546\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   183 time: 86.3795 loss : 0.0062544\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   184 time: 83.6128 loss : 0.0059254\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   185 time: 86.9621 loss : 0.0051400\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   186 time: 85.5099 loss : 0.0059277\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   187 time: 83.3836 loss : 0.0052930\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   188 time: 83.0130 loss : 0.0050724\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   189 time: 84.4761 loss : 0.0050526\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   190 time: 83.9109 loss : 0.0063928\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   191 time: 86.4207 loss : 0.0052732\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   192 time: 85.1318 loss : 0.0056157\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   193 time: 85.8745 loss : 0.0066620\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   194 time: 85.5340 loss : 0.0063495\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   195 time: 84.3656 loss : 0.0054227\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   196 time: 84.0436 loss : 0.0044933\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   197 time: 85.2225 loss : 0.0071711\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   198 time: 85.2874 loss : 0.0063883\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   199 time: 85.5560 loss : 0.0055903\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   200 time: 84.7789 loss : 0.0049764\n",
      "Accuracy of the network on the 10000 test images: 93 %\n"
     ]
    }
   ],
   "source": [
    "testCorrect = []\n",
    "trainingLoss = []\n",
    "print('hing')\n",
    "for epoch in range(setEpoch):\n",
    "    start = time.time()\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    #print(epoch)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # [inputs, labels]  data   ;\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        #print(i)\n",
    "        # (Gradient)  0 \n",
    "        \n",
    "\n",
    "        #  +  +   \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #  .\n",
    "        running_loss += loss.item()\n",
    "                  \n",
    "    step_lr_scheduler.step()\n",
    "    \n",
    "    print('epoch : %5d time: %0.4f loss : %.7f' %(epoch + 1, time.time() - start,(running_loss /int(50000/batchSize))))\n",
    "    trainingLoss.append((running_loss /int(50000/batchSize)))\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    testCorrect.append(100 * correct / total)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 93.170000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 96 %\n",
      "Accuracy of   car : 94 %\n",
      "Accuracy of  bird : 87 %\n",
      "Accuracy of   cat : 87 %\n",
      "Accuracy of  deer : 92 %\n",
      "Accuracy of   dog : 86 %\n",
      "Accuracy of  frog : 94 %\n",
      "Accuracy of horse : 96 %\n",
      "Accuracy of  ship : 96 %\n",
      "Accuracy of truck : 93 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels =  data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../model/denseNetBCCIFAR10Rev1.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   201 time: 86.1131 loss : 0.0052231\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   202 time: 85.4969 loss : 0.0055791\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   203 time: 85.6240 loss : 0.0067457\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   204 time: 85.4650 loss : 0.0058163\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   205 time: 85.6663 loss : 0.0061803\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   206 time: 85.7904 loss : 0.0058150\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   207 time: 84.7634 loss : 0.0072610\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   208 time: 84.8469 loss : 0.0050706\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   209 time: 85.1819 loss : 0.0055232\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   210 time: 85.2907 loss : 0.0054454\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   211 time: 84.7094 loss : 0.0064893\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   212 time: 84.4586 loss : 0.0057414\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   213 time: 85.4106 loss : 0.0069377\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   214 time: 86.3445 loss : 0.0088692\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   215 time: 86.8024 loss : 0.0075718\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   216 time: 85.8919 loss : 0.0072111\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   217 time: 84.5076 loss : 0.0065375\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "epoch :   218 time: 85.6144 loss : 0.0115232\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   219 time: 85.3777 loss : 0.0073907\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   220 time: 86.5791 loss : 0.0089927\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "epoch :   221 time: 85.5317 loss : 0.0086658\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "epoch :   222 time: 85.5782 loss : 0.0081607\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "epoch :   223 time: 85.2237 loss : 0.0087597\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "epoch :   224 time: 84.8449 loss : 0.0116718\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "epoch :   225 time: 84.1718 loss : 0.0109180\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "epoch :   226 time: 84.3319 loss : 0.0070350\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   227 time: 85.0135 loss : 0.0051384\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   228 time: 86.0851 loss : 0.0045314\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   229 time: 85.9003 loss : 0.0038267\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   230 time: 85.6294 loss : 0.0038376\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   231 time: 84.7596 loss : 0.0032528\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   232 time: 86.1865 loss : 0.0030734\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   233 time: 84.7002 loss : 0.0029000\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   234 time: 86.4647 loss : 0.0031366\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   235 time: 84.1987 loss : 0.0027750\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   236 time: 84.3192 loss : 0.0026670\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   237 time: 85.4055 loss : 0.0021682\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   238 time: 86.8552 loss : 0.0027712\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   239 time: 84.3652 loss : 0.0021626\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   240 time: 85.7401 loss : 0.0023081\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   241 time: 83.6100 loss : 0.0022574\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   242 time: 84.9225 loss : 0.0024010\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   243 time: 84.6475 loss : 0.0020527\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   244 time: 82.7726 loss : 0.0021447\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   245 time: 82.5914 loss : 0.0019122\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   246 time: 82.9460 loss : 0.0018743\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   247 time: 86.4948 loss : 0.0019271\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   248 time: 86.8774 loss : 0.0019437\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   249 time: 84.9077 loss : 0.0018147\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   250 time: 85.8801 loss : 0.0020453\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   251 time: 86.3193 loss : 0.0017983\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   252 time: 84.8756 loss : 0.0016942\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   253 time: 83.6827 loss : 0.0020800\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   254 time: 85.1400 loss : 0.0018230\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   255 time: 85.3411 loss : 0.0017654\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   256 time: 85.2266 loss : 0.0019652\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   257 time: 85.6968 loss : 0.0017415\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   258 time: 84.7564 loss : 0.0016209\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   259 time: 85.4219 loss : 0.0019405\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   260 time: 85.1166 loss : 0.0017006\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   261 time: 84.9654 loss : 0.0015559\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   262 time: 83.3901 loss : 0.0016162\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   263 time: 85.3524 loss : 0.0017880\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   264 time: 86.6384 loss : 0.0014374\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   265 time: 85.8732 loss : 0.0018416\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   266 time: 86.7778 loss : 0.0016829\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   267 time: 85.0344 loss : 0.0016918\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   268 time: 84.0499 loss : 0.0014753\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   269 time: 86.1906 loss : 0.0017186\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   270 time: 84.7419 loss : 0.0016987\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   271 time: 85.0180 loss : 0.0014493\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   272 time: 85.4739 loss : 0.0015680\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   273 time: 85.6401 loss : 0.0014583\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   274 time: 84.9871 loss : 0.0015572\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   275 time: 86.0053 loss : 0.0015143\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   276 time: 84.7833 loss : 0.0015032\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   277 time: 86.3089 loss : 0.0012096\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   278 time: 86.3073 loss : 0.0013802\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   279 time: 85.8258 loss : 0.0018557\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   280 time: 86.2644 loss : 0.0018232\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   281 time: 85.3106 loss : 0.0015277\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   282 time: 84.7793 loss : 0.0015576\n",
      "Accuracy of the network on the 10000 test images: 93 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   283 time: 84.4734 loss : 0.0016236\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   284 time: 86.7196 loss : 0.0013790\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   285 time: 84.3812 loss : 0.0015662\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   286 time: 85.0443 loss : 0.0013488\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   287 time: 84.8823 loss : 0.0017182\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   288 time: 86.3123 loss : 0.0013612\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   289 time: 85.0467 loss : 0.0013547\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   290 time: 84.3854 loss : 0.0015482\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   291 time: 86.4031 loss : 0.0014095\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   292 time: 85.1683 loss : 0.0011925\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   293 time: 86.1373 loss : 0.0013470\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   294 time: 85.7239 loss : 0.0013195\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   295 time: 85.7110 loss : 0.0013588\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   296 time: 86.5886 loss : 0.0016437\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   297 time: 84.7600 loss : 0.0014337\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   298 time: 85.0488 loss : 0.0016381\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   299 time: 86.3178 loss : 0.0010595\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "epoch :   300 time: 85.9242 loss : 0.0012288\n",
      "Accuracy of the network on the 10000 test images: 93 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200,300):\n",
    "    start = time.time()\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    #print(epoch)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # [inputs, labels]  data   ;\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        #print(i)\n",
    "        # (Gradient)  0 \n",
    "        \n",
    "\n",
    "        #  +  +   \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #  .\n",
    "        running_loss += loss.item()\n",
    "                  \n",
    "    step_lr_scheduler.step()\n",
    "    \n",
    "    print('epoch : %5d time: %0.4f loss : %.7f' %(epoch + 1, time.time() - start,(running_loss /int(50000/batchSize))))\n",
    "    trainingLoss.append((running_loss /int(50000/batchSize)))\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    testCorrect.append(100 * correct / total)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"denseNetBC_accu.csv\",'w')\n",
    "f.write(\"testAccu, trainLoss\\n\")\n",
    "for i in  range(len(testCorrect)):\n",
    "    f.write(\"%2.2f, %.7f\\n\" %(testCorrect[i], trainingLoss[i]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50.36, 63.59, 68.67, 68.42, 75.55, 82.18, 81.57, 83.3, 83.59, 83.66, 82.44, 84.27, 84.02, 78.9, 82.79, 84.17, 85.42, 79.69, 84.75, 84.97, 83.9, 85.87, 85.47, 87.16, 83.32, 83.9, 84.76, 85.57, 84.5, 84.85, 83.44, 85.56, 83.04, 85.78, 86.53, 85.84, 85.7, 87.03, 82.29, 83.65, 87.89, 85.76, 87.46, 86.56, 87.79, 86.15, 82.46, 86.67, 87.33, 83.18, 87.53, 83.88, 87.92, 87.6, 89.3, 88.07, 86.54, 87.19, 85.96, 85.3, 83.73, 87.66, 86.27, 89.19, 87.04, 85.71, 86.77, 87.75, 87.58, 86.61, 88.06, 86.26, 85.7, 88.83, 85.98, 89.45, 84.77, 86.04, 87.04, 84.74, 87.27, 88.55, 84.7, 87.97, 87.2, 88.22, 88.29, 85.02, 88.18, 84.43, 87.39, 88.32, 85.81, 87.77, 87.28, 88.95, 86.82, 87.72, 87.67, 87.05, 87.84, 88.91, 83.67, 86.91, 88.06, 86.29, 85.29, 88.13, 88.7, 88.94, 85.76, 87.33, 87.54, 86.29, 88.32, 86.81, 87.02, 86.62, 88.42, 86.07, 88.33, 88.63, 89.4, 89.37, 87.02, 88.66, 87.65, 88.93, 88.08, 87.73, 88.51, 78.27, 88.53, 88.02, 89.43, 89.03, 88.57, 87.12, 87.7, 87.29, 87.43, 86.67, 87.34, 87.33, 89.49, 88.85, 89.63, 86.61, 86.97, 88.3, 93.05, 93.22, 93.36, 93.39, 93.45, 93.35, 93.42, 93.47, 93.4, 93.49, 93.38, 93.59, 93.62, 93.46, 93.48, 93.41, 93.65, 93.6, 93.75, 93.52, 93.55, 93.31, 93.32, 93.44, 93.35, 93.3, 93.54, 93.53, 93.39, 93.7, 93.6, 93.41, 93.48, 93.44, 93.45, 93.34, 93.25, 93.35, 93.48, 93.33, 93.19, 93.35, 93.31, 93.52, 93.33, 93.23, 93.32, 93.33, 93.34, 93.17, 93.12, 93.42, 93.12, 93.27, 93.16, 93.73, 93.21, 93.39, 93.49, 93.41, 93.15, 93.27, 93.15, 93.32, 93.19, 93.27, 92.86, 93.02, 93.28, 92.9, 92.97, 92.81, 92.95, 92.81, 92.6, 93.1, 93.2, 93.4, 93.38, 93.55, 93.61, 93.55, 93.54, 93.61, 93.52, 93.55, 93.52, 93.6, 93.69, 93.68, 93.55, 93.5, 93.71, 93.59, 93.73, 93.58, 93.72, 93.74, 93.76, 93.71, 93.65, 93.77, 93.82, 93.67, 93.91, 93.76, 93.82, 93.83, 93.87, 93.74, 93.72, 93.66, 93.71, 93.71, 93.8, 93.65, 93.75, 93.79, 93.73, 93.74, 93.52, 93.8, 93.88, 93.76, 93.7, 93.81, 93.71, 93.7, 93.79, 93.88, 93.72, 93.75, 93.79, 93.48, 93.73, 93.73, 93.8, 93.89, 93.86, 93.83, 93.89, 93.9, 93.9, 93.82, 93.69, 93.93, 93.85, 93.76, 93.78, 93.83]\n",
      "[1.631717345015493, 1.0881299617653772, 0.8345922801009213, 0.6924507469892807, 0.604031303246409, 0.5404195356422441, 0.5017599451251891, 0.46134178611365234, 0.4380511012829831, 0.42567927095557295, 0.39091370892967364, 0.3783311649737224, 0.3652835799316743, 0.3517693936557684, 0.3468471519773046, 0.33152174712105076, 0.3346403049026042, 0.3161826551189496, 0.31691484054056845, 0.3081786896599392, 0.30584164244264705, 0.30215627308004794, 0.2992987057978762, 0.29403883765395566, 0.2893914167081195, 0.28604604876224576, 0.28834298233979794, 0.28477943486387386, 0.2759105582243349, 0.27361646459632283, 0.27090324161910523, 0.26617404136439443, 0.26763580490032474, 0.26724373381322536, 0.2612041417561786, 0.25851144283418465, 0.2563986367571064, 0.25860823767209634, 0.25981340260649155, 0.25046664514553835, 0.25306874156837733, 0.24659775311029522, 0.24638512556020184, 0.24717237287118707, 0.25028381219059803, 0.2436024232859343, 0.2537400493023872, 0.2414577163555558, 0.23493185164299574, 0.2380800927999917, 0.23736203761435043, 0.24280131127442045, 0.2319767751686857, 0.2301551235765791, 0.2368694047816813, 0.23375393052450674, 0.2245433223022389, 0.22813017730256507, 0.22986178065765836, 0.23494651239656303, 0.22518509947879672, 0.22626881257519985, 0.22517812892641972, 0.22567569119104502, 0.22407390002194655, 0.22361965801342654, 0.22501965595955428, 0.21605606984809786, 0.22087503417792148, 0.22514976311603827, 0.2169491265508109, 0.21925935681036432, 0.2146794998806051, 0.2222941094262957, 0.2119569189455384, 0.21828996595209907, 0.21486376100500018, 0.2160970576574952, 0.21732191086082545, 0.21073561029153354, 0.21626875540015028, 0.20698174769380792, 0.2058892246006622, 0.21093108598977595, 0.21431854856647695, 0.21597961235729435, 0.20581728607301675, 0.21235423281826984, 0.21256685836500608, 0.2111684331639399, 0.20784766413032932, 0.21137786313185467, 0.20930017754149347, 0.21560505919263395, 0.20825831207629203, 0.2118452345515946, 0.20309798080812802, 0.20231253218273043, 0.20277101566082537, 0.21147610257151947, 0.2047401944583189, 0.20620077495462, 0.202484974058085, 0.20307468443574733, 0.20964598885609764, 0.20086597885445198, 0.20151832888186666, 0.20362077787919172, 0.20352293498022303, 0.2067762735739789, 0.20798469475552764, 0.2019949547812896, 0.2034469308920691, 0.20598435990044922, 0.19868754795376836, 0.20203647224969504, 0.20762211005185538, 0.20041995908630947, 0.20197339591578545, 0.20152242086283986, 0.20521157811110824, 0.19667139524896837, 0.20068595062812525, 0.19693998939974208, 0.19852768601646956, 0.20139498253580704, 0.20020987175013893, 0.19689083912155844, 0.19448131692050818, 0.20448025458142943, 0.20612670836562383, 0.1984457151723427, 0.19708733917446508, 0.200630922948467, 0.20206207700941842, 0.2026049741919459, 0.19799803910960614, 0.19529088352366844, 0.20161800128473362, 0.1951088462640244, 0.20008166778770664, 0.19744064139438347, 0.19068451940765302, 0.19415443104413957, 0.19971824970177438, 0.19298014299951197, 0.2038919239921469, 0.2009063454895792, 0.2040386278797585, 0.19522624679396308, 0.07820007443981347, 0.04744327881596458, 0.03562111954148692, 0.02828855661343826, 0.024287992318026082, 0.018922047033696106, 0.018471700295557895, 0.015170866125066516, 0.014538130957857442, 0.013159088218028964, 0.013333551986345714, 0.01133915336466324, 0.011114269032330275, 0.008839617040909816, 0.008624006053206252, 0.008426454371358917, 0.008732616524575767, 0.007789685473170384, 0.00871472250045338, 0.008174303327609574, 0.007372283485268509, 0.006132380056663603, 0.007309080982788272, 0.006465261470569386, 0.006543066715118064, 0.00654012608257207, 0.007014611170707072, 0.006397165825516558, 0.007196018322062096, 0.00651736697241683, 0.006757309762868319, 0.006154556208971063, 0.006254383161301497, 0.005925379951082638, 0.0051399853066201396, 0.005927678789089645, 0.00529303971234418, 0.005072380569924466, 0.005052572919983565, 0.00639280216069594, 0.005273164143826378, 0.005615748116858638, 0.00666204033832086, 0.006349465505681484, 0.005422728668025453, 0.00449327919417551, 0.0071711227650755344, 0.006388259519764464, 0.005590292592932412, 0.004976385586660131, 0.0052230699409977575, 0.0055791066909416384, 0.006745714994765122, 0.005816254159018264, 0.006180307180376272, 0.005814999742636149, 0.00726095561257703, 0.005070648185918334, 0.005523205523721387, 0.00544539434541966, 0.006489334272628557, 0.00574137668260081, 0.006937701560356553, 0.008869208481339272, 0.007571760278848619, 0.007211114061702992, 0.006537533991239135, 0.01152315616092517, 0.0073906737600337525, 0.008992744841053606, 0.008665791179665224, 0.008160730730861463, 0.008759670426995134, 0.011671848308948487, 0.010917972067368626, 0.007035009863472779, 0.005138373610571924, 0.0045313625745522996, 0.003826745221732368, 0.0038376360578359927, 0.003252840912143644, 0.0030734134258442436, 0.0028999541980356323, 0.003136595570400033, 0.0027749817937650694, 0.0026669635529249485, 0.0021682249026780853, 0.002771172009494332, 0.0021625852567667236, 0.002308076345355807, 0.002257444985239515, 0.0024009812933305772, 0.0020527323843880286, 0.002144663085476537, 0.0019121609637740328, 0.0018743094099773793, 0.001927075909972954, 0.0019437159470040422, 0.0018147232437866446, 0.0020452954647788317, 0.0017982579567368297, 0.0016942083950079356, 0.0020800391438675903, 0.0018230450462440218, 0.0017653605191182541, 0.0019652062738445444, 0.001741518456102486, 0.0016209060438311207, 0.0019404945153356668, 0.001700576261239229, 0.0015559016933209154, 0.0016162324692009353, 0.0017880118534293278, 0.0014374228945614892, 0.0018416082298099309, 0.0016829234460862437, 0.0016918006268414583, 0.0014752723877622285, 0.0017185501477629823, 0.0016986873911910723, 0.0014493099954003103, 0.0015679842264185184, 0.0014582948518318342, 0.0015571544593183393, 0.0015143292184523218, 0.001503200269043064, 0.0012096482187166104, 0.0013802444392984564, 0.001855737192224754, 0.0018231867980712812, 0.0015277218087916184, 0.001557580468443994, 0.001623576776471547, 0.0013790348408774743, 0.0015661581377671714, 0.0013487704775550149, 0.0017181719330147806, 0.001361157807131583, 0.0013546598419337205, 0.0015482161666305972, 0.0014095341025943486, 0.0011925378315885303, 0.001347027785799415, 0.0013194872250019665, 0.001358840915060837, 0.0016437071958668864, 0.0014336878355120269, 0.0016380649980601214, 0.0010594671804376814, 0.001228812190008835]\n"
     ]
    }
   ],
   "source": [
    "print(testCorrect)\n",
    "print(trainingLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
